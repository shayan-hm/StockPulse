{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b00739-489f-4cc9-9ab7-c0d6c5c71c1a",
   "metadata": {},
   "source": [
    "### part1 : train lightgbm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8ba989-b337-4247-964f-df1aaaf9a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44353c64-f922-4f87-ad99-4d8ec03dfa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODELS_DIR = os.path.join(\"outputs\", \"models\")\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "QUANTILES = [0.1, 0.5, 0.9]\n",
    "FEATURES = [\"Lag_1\",\"Lag_2\",\"Lag_3\",\"RollingMean_3\",\"RollingStd_3\",\"USD_Trend\",\"Holiday_Ratio\",\"Week_Index\",\"Category\"]\n",
    "TARGET = \"Demand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a0db78-7be1-41f2-9f85-6074f6ec5f61",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1) Load prepared ML-ready file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded rows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.xlsx'"
     ]
    }
   ],
   "source": [
    "# 1) Load prepared ML-ready file\n",
    "df = pd.read_excel('data.xlsx')\n",
    "print(\"Loaded rows:\", len(df), \"columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e7117-07ab-4fb3-86ed-fdbd471f8f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Train set (weeks <= 18), Predict frame (week == 19)\n",
    "train_df = df[df['Week_Index'] <= 18].copy()\n",
    "pred_df  = df[df['Week_Index'] == 19].copy()\n",
    "print(\"Train rows:\", len(train_df), \"Predict rows:\", len(pred_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c7aab-7cd1-4cf0-9123-dc1d4c9139cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Basic feature check & NA handling\n",
    "# keep only FEATURES that exist\n",
    "features = [c for c in FEATURES if c in train_df.columns]\n",
    "print(\"Using features:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358614c-fdc3-4b6e-8585-d77437d9e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Optional: simple rolling validation for q50 (point model) to get a quick sense of error\n",
    "# we'll train a regression model on train_df and evaluate via a small random split (approximation)\n",
    "X = train_df[features]\n",
    "y = train_df[TARGET]\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.12, random_state=RANDOM_SEED, shuffle=True)\n",
    "dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
    "dvalid = lgb.Dataset(X_val, label=y_val)\n",
    "params_reg = {\"objective\":\"regression\",\"metric\":\"rmse\",\"learning_rate\":0.05,\"num_leaves\":31,\"verbosity\":-1,\"seed\":RANDOM_SEED}\n",
    "bst = lgb.train(\n",
    "    params_reg,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[dtrain, dvalid],\n",
    ")\n",
    "\n",
    "val_pred = bst.predict(X_val)\n",
    "print(\"Quick validation MAE (q50 point reg):\", mean_absolute_error(y_val, val_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe157104-b290-4b7e-a87e-62955c6b5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 5) Train quantile models (global) for each quantile and predict week 19\n",
    "predictions = pred_df[['SKU-index', 'Week_Index']].copy()\n",
    "\n",
    "for q in QUANTILES:\n",
    "    print(f\"\\nTraining quantile model alpha={q} ...\")\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"quantile\",\n",
    "        \"metric\": \"quantile\",\n",
    "        \"alpha\": q,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 31,\n",
    "        \"seed\": RANDOM_SEED,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "\n",
    "    dtrain_q = lgb.Dataset(train_df[features], label=train_df[TARGET])\n",
    "\n",
    "    # training\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        dtrain_q,\n",
    "        num_boost_round=500,\n",
    "        callbacks=[lgb.log_evaluation(100)]  # Ù†Ù…Ø§ÛŒØ´ Ù‡Ø± 100 iteration\n",
    "    )\n",
    "\n",
    "    # save model\n",
    "    model_fname = os.path.join(MODELS_DIR, f\"lgb_q{int(q*100)}.pkl\")\n",
    "    joblib.dump(model, model_fname)\n",
    "    print(\"âœ… Saved model:\", model_fname)\n",
    "\n",
    "    # predict\n",
    "    pred_vals = model.predict(pred_df[features].fillna(0))\n",
    "    colname = f\"q{int(q*100)}_ml\"\n",
    "    predictions[colname] = pred_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8507bbb4-6cc4-48fd-9a48-30d9074fb787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Postprocess predictions: remove negatives, round if you want (keep raw for now)\n",
    "for c in predictions.columns:\n",
    "    if c.startswith(\"q\"):\n",
    "        predictions[c] = predictions[c].clip(lower=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa29f2d-e0a8-4594-a943-1328883ec6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Save forecast table\n",
    "out_file = os.path.join(\"outputs\", \"forecast_ml.xlsx\")\n",
    "predictions.to_excel(out_file, index=False)\n",
    "print(\"Saved ML forecast for week19 to:\", out_file)\n",
    "print(predictions.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f314d-77b5-4bd4-b74d-b9af85de06e8",
   "metadata": {},
   "source": [
    "### part2 : train prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f408e93-e9cc-49cf-a301-873ba29063fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "# --- 1. Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "df = pd.read_excel(\"weekly_aggregate.xlsx\")\n",
    "\n",
    "# --- 2. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Prophet\n",
    "df = df.rename(columns={'week': 'ds', 'avg_demand': 'y'})\n",
    "\n",
    "# ðŸ”¹ ØªØ¨Ø¯ÛŒÙ„ Ø¹Ø¯Ø¯ Ù‡ÙØªÙ‡ Ø¨Ù‡ ØªØ§Ø±ÛŒØ® ÙˆØ§Ù‚Ø¹ÛŒ\n",
    "# ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ù‡ÙØªÙ‡ 1 Ø§Ø² Ø§Ø¨ØªØ¯Ø§ÛŒ Ø³Ø§Ù„ 2024 Ø´Ø±ÙˆØ¹ Ø´Ø¯Ù‡\n",
    "df['ds'] = pd.to_datetime('2025-01-21') + pd.to_timedelta((df['ds'] - 1) * 7, unit='D')\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Prophet\n",
    "model = Prophet(weekly_seasonality=True, yearly_seasonality=False, daily_seasonality=False)\n",
    "model.fit(df)\n",
    "\n",
    "# --- 4. Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‡ÙØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯\n",
    "future = model.make_future_dataframe(periods=4, freq='W')\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# --- 5. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡ÙØªÙ‡ Ø¨Ø¹Ø¯ÛŒ (Ù…Ø«Ù„Ø§Ù‹ Ù‡ÙØªÙ‡ 19)\n",
    "forecast_next = forecast.tail(1)[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "forecast_next.rename(columns={'yhat': 'predicted_avg_demand'}, inplace=True)\n",
    "# Ù‡Ù…Ø§Ù‡Ù†Ú¯â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "\n",
    "\n",
    "\n",
    "# --- 6. Ø®ÙˆØ§Ù†Ø¯Ù† Ù„ÛŒØ³Øª SKUÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ú¯Ø³ØªØ±Ø´ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ\n",
    "sku_template = pd.read_excel(\"sku_week_template.xlsx\")\n",
    "\n",
    "# --- 7. Ø§ÙØ²ÙˆØ¯Ù† Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ù‡ ØªÙ…Ø§Ù… SKUÙ‡Ø§\n",
    "sku_template['predicted_avg_demand'] = forecast_next['predicted_avg_demand'].values[0]\n",
    "\n",
    "# --- 8. Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "sku_template.to_excel(\"outputs/forecast_prophet.xlsx\", index=False)\n",
    "\n",
    "\n",
    "print(\"âœ… Prophet Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09032cb8-2c45-46e3-b466-e5d2c66d1d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db537807-2f41-4539-a13f-606a758d9288",
   "metadata": {},
   "source": [
    "### make D_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6276a0c-7d54-413f-8c95-b667ed279b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ---\n",
    "ml = pd.read_excel(\"outputs/forecast_ml.xlsx\")              # Ø´Ø§Ù…Ù„ q10_mlØŒ q50_mlØŒ q90_ml\n",
    "prophet = pd.read_excel(\"outputs/forecast_prophet.xlsx\")    # Ø´Ø§Ù…Ù„ predicted_avg_demand\n",
    "mean3 = pd.read_excel(\"mean3.xlsx\")                         # Ø´Ø§Ù…Ù„ mean Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ù‡â€ŒÙ‡ÙØªÙ‡â€ŒØ§ÛŒ\n",
    "\n",
    "# --- 2. Ù‡Ù…Ø§Ù‡Ù†Ú¯â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ ---\n",
    "# Prophet Ùˆ Mean3 Ø§Ø² Ø³ØªÙˆÙ† Ù…Ø´ØªØ±Ú© SKU Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†\n",
    "# ÙˆÙ„ÛŒ ML Ø¯Ø§Ø±Ù‡: SKU-index  â†’ Ø¨Ø§ÛŒØ¯ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ú©Ù†ÛŒÙ…\n",
    "ml = ml.rename(columns={\"SKU-index\": \"SKU\"})\n",
    "\n",
    "# --- 3. ØªØ±Ú©ÛŒØ¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ---\n",
    "df = (\n",
    "    ml.merge(prophet[[\"SKU\", \"predicted_avg_demand\"]], on=\"SKU\", how=\"left\")\n",
    "      .merge(mean3[[\"SKU\", \"mean\"]], on=\"SKU\", how=\"left\")\n",
    ")\n",
    "\n",
    "# --- 4. ØªØ¹Ø±ÛŒÙ Ú©Ø§Ù„Ø§Ù‡Ø§ÛŒ Ù…Ù‡Ù… ---\n",
    "important_skus = list(range(1, 10)) + list(range(35, 39))\n",
    "\n",
    "# --- 5. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ù‡Ø§ÛŒÛŒ ---\n",
    "def compute_final_forecast(row):\n",
    "    if row[\"SKU\"] in important_skus:\n",
    "        # Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù„Ø§Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ø§Ø² q90_ml Ùˆ predicted_avg_demand Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†\n",
    "        ml_val = row[\"q90_ml\"]\n",
    "        prophet_val = row[\"predicted_avg_demand\"]\n",
    "    else:\n",
    "        # Ø¨Ø±Ø§ÛŒ Ø¨Ù‚ÛŒÙ‡ Ø§Ø² q50_ml Ùˆ predicted_avg_demand Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†\n",
    "        ml_val = row[\"q50_ml\"]\n",
    "        prophet_val = row[\"predicted_avg_demand\"]\n",
    "    mean_val = row[\"mean\"]\n",
    "    return 0.1 * ml_val + 0.1 * prophet_val + 0.8 * mean_val\n",
    "\n",
    "df[\"D_used\"] = df.apply(compute_final_forecast, axis=1)\n",
    "\n",
    "# --- 6. Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ ---\n",
    "df_out = df[[\"SKU\", \"Week_Index\", \"D_used\"]]\n",
    "df_out.to_excel(\"outputs/D_used_week19.xlsx\", index=False)\n",
    "\n",
    "print(\"âœ… ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ Ùˆ Ø¯Ø± Ù…Ø³ÛŒØ± outputs/D_used_week19.xlsx Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9668bd-4424-412e-b207-8f23ac1a86f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c24cc026-bc5a-43f9-801d-02acda6d495e",
   "metadata": {},
   "source": [
    "### make D_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c8744d-fbf6-4cfe-a802-3544589268d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ---\n",
    "d_used = pd.read_excel(\"outputs/D_used_week19.xlsx\")\n",
    "mean_long = pd.read_excel(\"mean per week.xlsx\")\n",
    "\n",
    "# --- 2. Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÛŒÚ©Ø³Ø§Ù† Ø¨ÙˆØ¯Ù† Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ ---\n",
    "d_used = d_used.rename(columns={\"SKU\": \"SKU-index\"})\n",
    "mean_long = mean_long.rename(columns={\"SKU\": \"SKU-index\"})\n",
    "\n",
    "# --- 3. Ø§Ø¯ØºØ§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ SKU ---\n",
    "df = d_used.merge(mean_long, on=\"SKU-index\", how=\"left\")\n",
    "\n",
    "# --- 4. Ù…Ø­Ø§Ø³Ø¨Ù‡ D_input Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¶Ø±Ø§ÛŒØ¨ Ø«Ø§Ø¨Øª ---\n",
    "df[\"D_input\"] = 0.8 * df[\"mean\"] + 0.2 * df[\"D_used\"]\n",
    "\n",
    "# --- 5. Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ ---\n",
    "df_out = df[[\"SKU-index\", \"Week_Index\", \"D_input\"]]\n",
    "df_out.to_excel(\"outputs/D_input_week19.xlsx\", index=False)\n",
    "\n",
    "print(\"âœ… ÙØ§ÛŒÙ„ D_input_week19.xlsx Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ Ùˆ Ø¯Ø± Ù…Ø³ÛŒØ± outputs Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
